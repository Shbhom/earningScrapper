name: Hourly Web Scraper

on:
  schedule:
    - cron: '0 * * * *'  # Runs every hour
jobs:
  scrape:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout Repository
        uses: actions/checkout@v2

      - name: Set up Node.js
        uses: actions/setup-node@v2
        with:
          node-version: '14'  # Choose the appropriate Node.js version

      - name: Install Dependencies
        run: npm install

      - name: Run Scraper
        run: node scrapper.js

      - name: Run Scraper and Capture Output
        id: scraper
        run: |
          scraped_data=$(node scrapper.js)
          echo "::set-output name=data::$scraped_data"
        continue-on-error: true  # This allows the workflow to continue even if the script fails

      - name: Append Successful Data to File
        if: steps.scraper.outcome == 'success'  # Only run this step if the scraper step was successful
        run: echo "${{ steps.scraper.outputs.data }}" > scraped_data.txt
