name: Hourly Web Scraper

on:
  schedule:
    - cron: '0 * * * *'  # Runs every hour
jobs:
  scrape:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout Repository
        uses: actions/checkout@v2

      - name: Set up Node.js
        uses: actions/setup-node@v2
        with:
          node-version: '16'  # Choose the appropriate Node.js version

      - name: Install Dependencies
        run: npm install

      - name: Run Scraper
        run: node scrapper.js

      - name: Append Successful Data to File
        # if: steps.scraper.outcome == 'success'  # Only run this step if the scraper step was successful
        run: |
          git config --local user.email "action@github.com"
          git config --local user.name "GitHub Action"
          git remote add origin https://github.com/Shbhom/earningScrapper.git
          git add scraped_data.txt
          git commit -m "Update scraped data [skip ci]"
          git push https://Shbhom:${{ secrets.PAT_TOKEN }}@github.com/Shbhom/earningScrapper.git HEAD:main
